# @license BSD-3 https://opensource.org/licenses/BSD-3-Clause
# Copyright (c) 2023, Institute of Automatic Control - RWTH Aachen University
# All rights reserved. 

using Base.Filesystem
using DataFrames
using FileIO
using ImageCore
using ImageIO
using JSON
using SciGL
using StaticArrays

dataset_path(dataset_name) = joinpath(pwd(), "datasets", dataset_name)
datasubset_path(dataset_name, subset_name="test") = joinpath(dataset_path(dataset_name), subset_name)

"""
    scene_paths(dataset_name, [subset_name="test"])
Returns a vector of the full paths to the scene directories of the datasets subset.
"""
scene_paths(dataset_name, subset_name="test") = readdir(datasubset_path(dataset_name, subset_name); join=true)

"""
    lpad_bop(number)
Pads the number with zeros from the left for a total length of six digits.
`pad_bop(42) = 000042`
"""
lpad_bop(number) = lpad(number, 6, "0")

"""
    scene_path(dataset_name, [subset_name="test", scene_number=1])
Returns the path to the scene directory with the given number of the datasets subset.
"""
scene_path(dataset_name, subset_name="test", scene_number=1) = joinpath(datasubset_path(dataset_name, subset_name), lpad_bop(scene_number))

"""
    image_dataframe(scene_path)
Load the image information as a DataFrame with the columns `img_id, depth_path, color_path, img_size` with `img_size=(width, height)`.
`color_path` either contains rgb or grayscale images.
"""
function image_dataframe(scene_path)
    depth_dir = joinpath(scene_path, "depth")
    rgb_dir = joinpath(scene_path, "rgb")
    gray_dir = joinpath(scene_path, "gray")
    depth_paths = readdir(depth_dir; join=true)
    # Depending on the dataset either gray or rgb is available
    color_paths = isdir(rgb_dir) ? readdir(rgb_dir; join=true) : readdir(gray_dir; join=true)
    img_ids = @. parse(Int, depth_paths |> splitext |> first |> splitpath |> last)
    img_sizes = map(depth_paths) do img_path
        # ImageIO loads transposed
        img = img_path |> load |> transpose
        size(img)
    end
    DataFrame(img_id=img_ids, depth_path=depth_paths, color_path=color_paths, img_size=img_sizes)
end

"""
    camera_dataframe(scene_path, img_df)
Load the camera information as a DataFrame with the columns `img_id, camera, depth_scale`.
`img_df` is the DataFrame generated by `image_dataframe` for the same `scene_path`.
"""
function camera_dataframe(scene_path, img_df)
    img_sizes = Dict(img_df.img_id .=> img_df.img_size)
    json_cams = JSON.parsefile(joinpath(scene_path, "scene_camera.json"))
    img_ids = parse.(Int, keys(json_cams))
    df = DataFrame(img_id=Int[], camera=CvCamera[], depth_scale=Float32[])
    for img_id in img_ids
        width, height = img_sizes[img_id]
        json_cam = json_cams[string(img_id)]
        cam_K = json_cam["cam_K"] .|> Float32
        cv_cam = CvCamera(width, height, cam_K[1], cam_K[5], cam_K[3], cam_K[6]; s=cam_K[4])
        scale = json_cam["depth_scale"] .|> Float32
        push!(df, (img_id, cv_cam, scale))
    end
    df
end

"""
    gt_dataframe(scene_path)
Load the ground truth information for each object and image as a DataFrame with the columns `img_id, obj_id, cam_R_m2c, cam_t_m2c, mask_path, mask_visib_path`.
"""
function gt_dataframe(scene_path)
    gt_json = JSON.parsefile(joinpath(scene_path, "scene_gt.json"))
    df = DataFrame(img_id=Int[], obj_id=Int[], gt_id=Int[], cam_R_m2c=QuatRotation[], cam_t_m2c=Vector{Float32}[], mask_path=String[], mask_visib_path=String[])
    for (img_id, body) in gt_json
        img_id = parse(Int, img_id)
        for (gt_id, gt) in enumerate(body)
            obj_id = gt["obj_id"]
            # Saved row-wise, Julia is column major
            cam_R_m2c = reshape(gt["cam_R_m2c"], 3, 3)' |> RotMatrix3 |> QuatRotation
            cam_t_m2c = Float32.(1e-3 * gt["cam_t_m2c"])
            # TODO to pose?
            # masks paths (mind julia vs python indexing)
            mask_filename = lpad_bop(img_id) * "_" * lpad_bop(gt_id - 1) * ".png"
            mask_path = joinpath(scene_path, "mask", mask_filename)
            mask_visib_path = joinpath(scene_path, "mask_visib", mask_filename)
            push!(df, (img_id, obj_id, gt_id, cam_R_m2c, cam_t_m2c, mask_path, mask_visib_path))
        end
    end
    df
end

load_depth_image(path, depth_scale) = Float32(1e-3 * depth_scale) .* (path |> load |> channelview |> rawview)
"""
    load_depth_image(df_row, img_id)
Load the depth image as a Matrix{Float32} of size (width, height) where each pixel is the depth in meters.
"""
load_depth_image(df_row::DataFrameRow) = load_depth_image(df_row.depth_path, df_row.depth_scale)

"""
    object_dataframe(dataset_name)
# TODO
"""
function object_dataframe(dataset_name)
    path = dataset_path(dataset_name)
    json = JSON.parsefile(joinpath(path, "models_eval", "models_info.json"))
    df = DataFrame(obj_id=Int[], diameter=Float32[], mesh=Mesh[])
    for (obj_id, data) in json
        obj_id = parse(Int, obj_id)
        diameter = Float32(1e-3 .* data["diameter"])
        filename = "obj_" * lpad_bop(obj_id) * ".ply"
        mesh_file = joinpath(path, "models_eval", filename)
        mesh = Scale(Float32(1e-3))(load(mesh_file))
        # TODO It makes more sense to keep the mesh in memory so replace mesh_file & scale in Parameters.jl
        push!(df, (obj_id, diameter, mesh))
    end
    df
end

# TODO support support multiple modalities, i.e. depth_img_path & color_img_path ?
function scene_dataframe(dataset_name="lm", subset_name="test", scene_number=1)
    path = scene_path(dataset_name, subset_name, scene_number)
    # Per image
    img_df = MCMCDepth.image_dataframe(path)
    cam_df = MCMCDepth.camera_dataframe(path, img_df)
    img_cam_df = innerjoin(img_df, cam_df; on=:img_id)
    # Per evaluation
    gt_df = gt_dataframe(path)
    gt_img_df = leftjoin(gt_df, img_cam_df, on=:img_id)
    # Per object
    obj_df = object_dataframe(dataset_name)
    leftjoin(gt_img_df, obj_df, on=:obj_id)
end